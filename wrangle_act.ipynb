{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Project - WeRateDogs\n",
    "## Michael Mosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/25351968/how-to-display-full-non-truncated-dataframe-information-in-html-when-convertin/25352191\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import WeRateDogs Twitter archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import image prediction file from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.codementor.io/aviaryan/downloading-files-from-urls-in-python-77q3bs0un\n",
    "\n",
    "import requests\n",
    "import os\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "r = requests.get(url)\n",
    "open('image-predictions.tsv', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred = pd.read_csv('image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tweet JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: Dhaval P's answer on his question: https://knowledge.udacity.com/questions/47704\n",
    "import json\n",
    "data = []\n",
    "with open('tweet_json.txt') as f:    \n",
    "        for line in f:         \n",
    "            data.append(json.loads(line))\n",
    "df_twit_JSON = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assess Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing WeRateDogs Twitter Archive Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Issues:\n",
    "- Dog names ('name') has 745 extracted as a non-null 'None', and several dog names extracted as 'a', 'the', and 'an'. Most of the Nones are appropriate, and most of the 'a', 'the', and 'an' entries should also be changed to 'None'. These are the 'a' or 'an' names that need to be changed to real ones:\n",
    "    - 649 a - Forrest\n",
    "    - 1853 a - Wylie\n",
    "    - 1955 a - Kip\n",
    "    - 2034 a - Yacōb\n",
    "    - 2066 a - Rufus\n",
    "    - 2116 a - Spork\n",
    "    - 2125 a - Cherokee\n",
    "    - 2128 a - Hemry\n",
    "    - 2146 a - Alphred\n",
    "    - 2161 a - Alfredo\n",
    "    - 2191 a - Leroi\n",
    "    - 2198 a - Toblerone\n",
    "    - 2218 a - Chuk\n",
    "    - 2235 a - Alfonso\n",
    "    - 2249 a - Cheryl\n",
    "    - 2255 a - Jessiga\n",
    "    - 2264 a - Klint\n",
    "    - 2273 a - Kohl\n",
    "    - 2287 a - Daryl\n",
    "    - 2304 a - Pepe\n",
    "    - 2311 a - Octaviath\n",
    "    - 2314 a - Johm\n",
    "    - 2204 an - 'Berta'\n",
    "- There are 181 retweet entries, and the project dictates only having original tweets. Should be removed.\n",
    "- There are 78 reply tweet entries, and I'm not sure if that fits into the definition of 'original tweet' even if it includes new photo, name and rating. Better to err on the side of caution and remove them.\n",
    "- Several ratings need to be adjusted, or rows removed due to non-ratings:\n",
    "    - Entry at index 313 extracted a rating of '960/0', and needs to be changed to the revised rating of '13/10'\n",
    "    - Entries at index 340 and 695 extracted a rating of '75/10', and needs to be changed to the actual rating of '9.75/10'\n",
    "    - Entry at index 342 actually doesn't have a rating ('11/15' was extracted, while it was simply a description of time). Row needs to be removed.\n",
    "    - Entry at index 516 actually doesn't have a rating ('24/7' was extracted, while it was simply a description of time). Row needs to be removed.\n",
    "    - Entry at index 763 extracted a rating of '27/10', and needs to be changed to the actual rating of '11.27/10'\n",
    "    - Entry at index 1068 extracted a rating of '9/11', and needs to be changed to the actual rating of '14/10'\n",
    "    - Entry at index 1165 extracted a rating of '4/20', and needs to be changed to the actual rating of '13/10'\n",
    "    - Entry at index 1202 extracted a rating of '50/50', and needs to be changed to the actual rating of '11/10'\n",
    "    - Entries at indices 1598 and 1663 were technically not officially given ratings by WeRateDogs, and should be removed.\n",
    "    - Entry at index 1662 extracted a rating of '7/11', and needs to be changed to the actual rating of '10/10'\n",
    "    - Entry at index 1712 extracted a rating of '26/10', and needs to be changed to the actual rating of '11.26/10'\n",
    "    - Entry at index 2335 extracted a rating of '1/2', and needs to be changed to the actual rating of '9/10'\n",
    "- Since some correct ratings contain decimal values, 'rating_numerator' and 'rating_denominator' need to be changed from int to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness Issues:\n",
    "- Dog types (i.e. doggo, puppo, etc.) are in separate variable columns, where if a dog is described as such, the value is the dogtype, whereas if it isn't, the value is a non-null 'None'. Instead the columns could either be framed as Boolean 1's and 0's, or all placed into one 'dog_type' variable column.\n",
    "    - Some entries have more than one dog type extracted from the text. This confirms that these columns are not mutually exclusive. This would be an issue had the extraction lumped all the categories for an entry together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing dog types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://stackoverflow.com/questions/33042633/selecting-last-n-columns-and-excluding-last-n-columns-in-dataframe\n",
    "dog_type_cols = df_WRD_twitter.columns[-5:].values\n",
    "\n",
    "for i in dog_type_cols:\n",
    "    print(df_WRD_twitter[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[(df_WRD_twitter['doggo'] == 'doggo') & (df_WRD_twitter['puppo'] == 'puppo')]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[(df_WRD_twitter['doggo'] == 'doggo') & (df_WRD_twitter['floofer'] == 'floofer')]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[(df_WRD_twitter['doggo'] == 'doggo') & (df_WRD_twitter['pupper'] == 'pupper')]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing dog names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter.name.value_counts().nlargest(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[df_WRD_twitter['name']=='None']['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[df_WRD_twitter['name']=='a']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[df_WRD_twitter['name']=='an']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[df_WRD_twitter['name']=='the']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing dog ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[df_WRD_twitter['rating_numerator'] >= 20][['rating_numerator','rating_denominator','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter[df_WRD_twitter['rating_denominator'] != 10][['rating_numerator','rating_denominator','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Image Prediction Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Issues:\n",
    "- There are 324 images that returned predictions that were not dogs ('p1_dog', 'p2_dog', 'p3_dog' all False). These rows are either evidence of the neural network discovering pictures that indeed don't contain dogs, or of the neural network having a difficult time finding the dog in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred.img_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_pred.tweet_id.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pict_false = df_img_pred[(df_img_pred.p1_dog == False) & (df_img_pred.p2_dog == False) & (df_img_pred.p3_dog == False)]\n",
    "all_pict_false.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Twitter JSON Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Issues:\n",
    "- There are 179 tweets that are retweets. These should be removed, as they are not originals.\n",
    "- There are 28-29 tweets that are original responses to other tweets. As they are not necessarily stand-alone originals, so may be up for removal, unless the image dataset has extracted photos associated with the tweet.\n",
    "- Essentially empty columns that should be dropped or ignored from merging: 'contributors', 'coordinates', 'geo', 'place'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness Issues:\n",
    "- Columns in which entries contain multiple pieces of information: 'entities', 'extended_entities', 'quoted_status', 'retweeted_status', 'user'. These columns could be made into their own datasets, or their contents could be sorted into unique variables that would be attached onto the end of the main JSON dataset entries to which they belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twit_JSON.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twit_JSON.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twit_JSON[df_twit_JSON.retweeted_status.isna() != True]['retweeted_status'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twit_JSON[df_twit_JSON.retweeted_status.isna() != True].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twit_JSON[df_twit_JSON.quoted_status.isna() != True].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twit_JSON.favorited.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Quality Issues:\n",
    "\n",
    "#### WeRateDogs Twitter Archive Data:\n",
    "- Dog names ('name') has 745 extracted as a non-null 'None', and several dog names extracted as 'a', 'the', and 'an'. Most of the Nones are appropriate, and most of the 'a', 'the', and 'an' entries should also be changed to 'None'. These are the 'a' or 'an' names that need to be changed to real ones:\n",
    "    - 649 a - Forrest\n",
    "    - 1853 a - Wylie\n",
    "    - 1955 a - Kip\n",
    "    - 2034 a - Yacōb\n",
    "    - 2066 a - Rufus\n",
    "    - 2116 a - Spork\n",
    "    - 2125 a - Cherokee\n",
    "    - 2128 a - Hemry\n",
    "    - 2146 a - Alphred\n",
    "    - 2161 a - Alfredo\n",
    "    - 2191 a - Leroi\n",
    "    - 2198 a - Toblerone\n",
    "    - 2218 a - Chuk\n",
    "    - 2235 a - Alfonso\n",
    "    - 2249 a - Cheryl\n",
    "    - 2255 a - Jessiga\n",
    "    - 2264 a - Klint\n",
    "    - 2273 a - Kohl\n",
    "    - 2287 a - Daryl\n",
    "    - 2304 a - Pepe\n",
    "    - 2311 a - Octaviath\n",
    "    - 2314 a - Johm\n",
    "    - 2204 an - 'Berta'\n",
    "- There are 181 retweet entries, and the project dictates only having original tweets. Should be removed.\n",
    "- There are 78 reply tweet entries, and I'm not sure if that fits into the definition of 'original tweet' even if it includes new photo, name and rating. Better to err on the side of caution and remove them.\n",
    "- Several ratings need to be adjusted, or rows removed due to non-ratings:\n",
    "    - Entry at index 313 extracted a rating of '960/0', and needs to be changed to the revised rating of '13/10'\n",
    "    - Entries at index 340 and 695 extracted a rating of '75/10', and needs to be changed to the actual rating of '9.75/10'\n",
    "    - Entry at index 342 actually doesn't have a rating ('11/15' was extracted, while it was simply a description of time). Row needs to be removed.\n",
    "    - Entry at index 516 actually doesn't have a rating ('24/7' was extracted, while it was simply a description of time). Row needs to be removed.\n",
    "    - Entry at index 763 extracted a rating of '27/10', and needs to be changed to the actual rating of '11.27/10'\n",
    "    - Entry at index 1068 extracted a rating of '9/11', and needs to be changed to the actual rating of '14/10'\n",
    "    - Entry at index 1165 extracted a rating of '4/20', and needs to be changed to the actual rating of '13/10'\n",
    "    - Entry at index 1202 extracted a rating of '50/50', and needs to be changed to the actual rating of '11/10'\n",
    "    - Entries at indices 1598 and 1663 were technically not officially given ratings by WeRateDogs, and should be removed.\n",
    "    - Entry at index 1662 extracted a rating of '7/11', and needs to be changed to the actual rating of '10/10'\n",
    "    - Entry at index 1712 extracted a rating of '26/10', and needs to be changed to the actual rating of '11.26/10'\n",
    "    - Entry at index 2335 extracted a rating of '1/2', and needs to be changed to the actual rating of '9/10'\n",
    "- Since some correct ratings contain decimal values, 'rating_numerator' and 'rating_denominator' need to be changed from int to float\n",
    "\n",
    "#### Image Prediction Data:\n",
    "- There are 324 images that returned predictions that were not dogs ('p1_dog', 'p2_dog', 'p3_dog' all False). These rows are either evidence of the neural network discovering pictures that indeed don't contain dogs, or of the neural network having a difficult time finding the dog in the image.\n",
    "\n",
    "#### Twitter JSON Data:\n",
    "- There are 179 tweets that are retweets. These should be removed, as they are not originals.\n",
    "- There are 28-29 tweets that are original responses to other tweets. As they are not necessarily stand-alone originals, so may be up for removal, unless the image dataset has extracted photos associated with the tweet.\n",
    "- Essentially empty columns that should be dropped or ignored from merging: 'contributors', 'coordinates', 'geo', 'place'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Tidiness Issues:\n",
    "\n",
    "#### WeRateDogs Twitter Archive Data:\n",
    "- Dog types (i.e. doggo, puppo, etc.) are in separate variable columns, where if a dog is described as such, the value is the dogtype, whereas if it isn't, the value is a non-null 'None'. Instead the columns could either be framed as Boolean 1's and 0's, or all placed into one 'dog_type' variable column.\n",
    "    - Some entries have more than one dog type extracted from the text. This confirms that these columns are not mutually exclusive. This would be an issue had the extraction lumped all the categories for an entry together.\n",
    "\n",
    "#### Twitter JSON Data:\n",
    "- Columns in which entries contain multiple pieces of information: 'entities', 'extended_entities', 'quoted_status', 'retweeted_status', 'user'. These columns could be made into their own datasets, or their contents could be sorted into unique variables that would be attached onto the end of the main JSON dataset entries to which they belong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert existing dog type columns in WeRateDogs Twitter Archive Data into boolean variables, then consolidate dog type column data into singular column 'dog_type' which contains the summary of dog types extracted per entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2 = df_WRD_twitter.copy()\n",
    "dog_type_cols = df_WRD_twitter2.columns[-4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dog_type_cols:\n",
    "    df_WRD_twitter2[i] = np.where(df_WRD_twitter2[i] == i, i, None)\n",
    "    df_WRD_twitter2[i] = df_WRD_twitter2[i].astype('bool')\n",
    "    \n",
    "subset = df_WRD_twitter2[df_WRD_twitter2.columns[-4:]].copy()\n",
    "\n",
    "# Reference: https://stackoverflow.com/questions/26762100/reconstruct-a-categorical-variable-from-dummies-in-pandas\n",
    "dog_type = []\n",
    "dog_type = subset.dot(subset.columns)\n",
    "dog_type = pd.Series(np.where(dog_type == None, None, dog_type))\n",
    "\n",
    "df_WRD_twitter2['dog_type'] = dog_type.astype('category');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2['dog_type'] = np.where(df_WRD_twitter2['dog_type'] == '', None, df_WRD_twitter2['dog_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2['dog_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2[df_WRD_twitter2['dog_type'].isna() != True].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change 'name' values of 'a', 'an', and 'the' to 'None'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2.name = np.where(df_WRD_twitter2.name == 'a', 'None', df_WRD_twitter2.name)\n",
    "df_WRD_twitter2.name = np.where(df_WRD_twitter2.name == 'the', 'None', df_WRD_twitter2.name)\n",
    "df_WRD_twitter2.name = np.where(df_WRD_twitter2.name == 'an', 'None', df_WRD_twitter2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2.name.value_counts().nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename some of the entries that had names 'a' or 'an' to their actual names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.tutorialspoint.com/How-to-create-Python-dictionary-from-list-of-keys-and-values\n",
    "keys = [649,1853,1955,2034,2066,2116,2125,2128,2146,2161,2191,2198,2204,2218,\n",
    "        2235,2249,2255,2264,2273,2287,2304,2311,2314]\n",
    "values = ['Forrest', 'Wylie', 'Kip', 'Yacōb', 'Rufus', 'Spork', 'Cherokee',\n",
    "          'Hemry', 'Alphred', 'Alfredo', 'Leroi', 'Toblerone', 'Berta', 'Chuk',\n",
    "          'Alfonso', 'Cheryl', 'Jessiga', 'Klint', 'Kohl', 'Daryl', 'Pepe',\n",
    "          'Octaviath', 'Johm']\n",
    "d = dict(zip(keys,values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in d.items():\n",
    "    df_WRD_twitter2.name.loc[k] = df_WRD_twitter2.name.loc[k].replace('None', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in d.items():\n",
    "    print(df_WRD_twitter2[['text','name']].iloc[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2.name.value_counts().nlargest(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change rating variables to dtype float64, and clean up incorrect ratings in the WeRateDogs Archive dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2.rating_numerator = df_WRD_twitter2.rating_numerator.astype('float')\n",
    "df_WRD_twitter2.rating_denominator = df_WRD_twitter2.rating_denominator.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2.rating_numerator.loc[313] = 13.00\n",
    "df_WRD_twitter2.rating_numerator.loc[[340,695]] = 9.75\n",
    "df_WRD_twitter2.rating_numerator.loc[763] = 11.27\n",
    "df_WRD_twitter2.rating_numerator.loc[1068] = 14.00\n",
    "df_WRD_twitter2.rating_numerator.loc[1165] = 13.00\n",
    "df_WRD_twitter2.rating_numerator.loc[1202] = 11.00\n",
    "df_WRD_twitter2.rating_numerator.loc[1662] = 10.00\n",
    "df_WRD_twitter2.rating_numerator.loc[1712] = 11.26\n",
    "df_WRD_twitter2.rating_numerator.loc[2335] = 9.00\n",
    "\n",
    "df_WRD_twitter2.rating_denominator.loc[[313,1068,1165,1202,1662,2335]] = 10.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2[df_WRD_twitter2['rating_denominator'] != 10][['rating_numerator','rating_denominator','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove entries with non-ratings: enties at indices, 342, 516, 1598, and 1663."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2 = df_WRD_twitter2.drop([342,516,1598,1663])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(342 in df_WRD_twitter2.index)\n",
    "print(516 in df_WRD_twitter2.index)\n",
    "print(1598 in df_WRD_twitter2.index)\n",
    "print(1663 in df_WRD_twitter2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the three datasets into one dataset:\n",
    "- Main DataFrame will be that of the edited WeRateDogs archive - `df_WRD_twitter2`\n",
    "- Tacked on to it will be the columns of interest from the JSON DataFrame - `df_twit_JSON`\n",
    "- Tacked on to that will be whole of the Image prediction DataFrame - `df_img_pred`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_master_df = df_WRD_twitter2.merge(df_twit_JSON[['id',\n",
    "                                                    'favorite_count', \n",
    "                                                    'retweet_count']],\n",
    "                                     left_on='tweet_id', right_on='id')\n",
    "pre_master_df = pre_master_df.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pre_master_df.merge(df_img_pred, on = 'tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WRD_twitter2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows which contain retweets and reply tweets, and then drop related empty columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/13851535/how-to-delete-rows-from-a-pandas-dataframe-based-on-a-conditional-expression\n",
    "master_df = master_df.drop(master_df[master_df.retweeted_status_timestamp.isna() == False].index)\n",
    "master_df = master_df.drop(master_df[master_df.in_reply_to_user_id.isna() == False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.drop(columns = ['retweeted_status_id',\n",
    "                                      'retweeted_status_user_id', \n",
    "                                      'retweeted_status_timestamp',\n",
    "                                      'in_reply_to_user_id',\n",
    "                                      'in_reply_to_status_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Dataset to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_csv('twitter_archive_master.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Master Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Dogtionary Dog Type Usage in Tweet Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dog_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/32891211/limit-the-number-of-groups-shown-in-seaborn-countplot\n",
    "ax = sns.countplot(data = df, x ='dog_type', \n",
    "                  color = sns.color_palette()[0], \n",
    "                  order=df.dog_type.value_counts().index);\n",
    "plt.xticks(rotation=30)\n",
    "plt.title('Dogtionary Dog Types in Tweets, \\n Sorted by Count')\n",
    "ax.set_xlabel('Dog Type(s)')\n",
    "ax.set_ylabel('Number of Tweets Dog Types Appeared In')\n",
    "\n",
    "#Reference: https://stackoverflow.com/questions/39519609/annotate-bars-with-values-on-pandas-on-seaborn-factorplot-bar-plot\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), \n",
    "                (p.get_x() + p.get_width() / 2.,\n",
    "                 p.get_height()+2), \n",
    "                ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/41801419/drawing-bar-charts-from-boolean-fields\n",
    "df1 = df[['pupper','puppo','doggo','floofer']].apply(pd.value_counts)\n",
    "ax = df1.loc[True].plot.bar();\n",
    "\n",
    "plt.title('Dogtionary Dog Types Appearances in Tweets, \\n Sorted by Dog Size')\n",
    "ax.set_xlabel('Dog Types')\n",
    "ax.set_ylabel('Number of Tweets Dog Types Appeared In')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), \n",
    "                (p.get_x() + p.get_width() / 2.,\n",
    "                 p.get_height()+2), \n",
    "                ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight #1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that when WeRateDogs does decide to describe dogs using Dogtionary nomenclature, the most common instances of doing so are for describing the smallest / youngest of dogs. This does not necessarily determine whether the majority of WeRateDog tweets are of 'puppers,' however, there is a greater chance of that being the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Averaged Ratings in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_rating'] = df.rating_numerator / df.rating_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(-.25, df.avg_rating.max()+0.25, 0.1)\n",
    "ax = plt.hist(df.avg_rating, bins = bins)\n",
    "\n",
    "plt.xlim([-0.05,1.5])\n",
    "locs, labels = plt.xticks()\n",
    "plt.xticks(locs, (locs*10).astype('int64'));\n",
    "\n",
    "plt.title('Histogram of Averaged Ratings,\\n sans outliers')\n",
    "plt.xlabel('Average Numerator (for a rating out of 10)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight #2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outside of a few outliers way out to the right, the general distribution of averaged ratings is left-skewed, with the densest ratings having the numerator value of 10-13. It is interesting to see that, despite the WeRateDogs Twitter account having a trademark of giving out ratings of 10 or greater, they still fairly often give out ratings below 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Favorite Counts vs Retweet Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.favorite_count, df.retweet_count);\n",
    "plt.title('Favorite Counts vs Retweet Counts')\n",
    "plt.xlabel('Favorites Count');\n",
    "plt.ylabel('Retweet Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.favorite_count, df.retweet_count, alpha = .25)\n",
    "plt.xlim([0,45000])\n",
    "plt.ylim([0,25000])\n",
    "plt.title('Favorite Counts vs Retweet Counts, \\n zoomed in')\n",
    "plt.xlabel('Favorites Count');\n",
    "plt.ylabel('Retweet Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['favorite_count','retweet_count']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight #3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that, although 'favorite_count' and 'retweet_count' have a quite high positive correlation (r = 0.913), there is also demonstrable heteroscedasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Distribution of Dog Type Relative to Averaged Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/8671808/matplotlib-avoiding-overlapping-datapoints-in-a-scatter-dot-beeswarm-plot\n",
    "plt.figure(figsize= (8,4))\n",
    "sns.swarmplot('dog_type', 'avg_rating', data=df)\n",
    "locs, labels = plt.yticks()\n",
    "plt.yticks(locs, (locs*10).astype('int64'));\n",
    "plt.xticks(rotation=30);\n",
    "plt.title('Dog Types and Their Spread of Averaged Ratings')\n",
    "plt.xlabel('Dog Type');\n",
    "plt.ylabel('Averaged Rating');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pupper - Mean Averaged Rating: ', df[df['pupper']==True]['avg_rating'].mean()*10)\n",
    "print('Puppo - Mean Averaged Rating: ', df[df['puppo']==True]['avg_rating'].mean()*10)\n",
    "print('Doggo - Mean Averaged Rating: ', df[df['doggo']==True]['avg_rating'].mean()*10)\n",
    "print('Floofer - Mean Averaged Rating: ', df[df['floofer']==True]['avg_rating'].mean()*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight #4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it might be due to a small non-representative sample size (one that may have lead to inflation in value due to rarity), but of the dogs described with Dogtionary taxonomy, 'puppos' have the highest mean average rating. They are followed by 'floofers,' then 'doggos,' and then 'puppers' by quite a large margin. That may be because 'puppers' appear more often, and therefore have more opportunities to get stale. Or, they are the youngest category, and therefore have the most room to grow, especially after - for instance - having been caught being naughty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review of Averaged Rating vs Retweet Count, then vs Favorite Count, all while incorporating Dog Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('avg_rating', 'retweet_count', data=df, hue = 'dog_type', color = sns.color_palette()[0]);\n",
    "plt.xlim([0.25,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('avg_rating', 'favorite_count', data=df, hue = 'dog_type', color = sns.color_palette()[0]);\n",
    "plt.xlim([0.25,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(x_vars=['avg_rating'], y_vars=['retweet_count'], data=df, hue = 'dog_type', height = 6);\n",
    "plt.xlim([0.25,1.5]);\n",
    "plt.ylim([0,22000]);\n",
    "locs, labels = plt.xticks()\n",
    "plt.xticks(locs, (locs*10).astype('int64'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pupper - Median Retweet Count: ', df[df['pupper']==True]['retweet_count'].median())\n",
    "print('Puppo - Median Retweet Count: ', df[df['puppo']==True]['retweet_count'].median())\n",
    "print('Doggo - Median Retweet Count: ', df[df['doggo']==True]['retweet_count'].median())\n",
    "print('Floofer - Median Retweet Count: ', df[df['floofer']==True]['retweet_count'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(x_vars=['avg_rating'], y_vars=['favorite_count'], data=df, hue = 'dog_type', height = 6);\n",
    "plt.xlim([0.25,1.5]);\n",
    "plt.ylim([0,55000]);\n",
    "locs, labels = plt.xticks()\n",
    "plt.xticks(locs, (locs*10).astype('int64'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pupper - Median Favorite Count: ', df[df['pupper']==True]['favorite_count'].median())\n",
    "print('Puppo - Median Favorite Count: ', df[df['puppo']==True]['favorite_count'].median())\n",
    "print('Doggo - Median Favorite Count: ', df[df['doggo']==True]['favorite_count'].median())\n",
    "print('Floofer - Median Favorite Count: ', df[df['floofer']==True]['favorite_count'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight #5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that as ratings increase, so do favorites and the retweets. However, it's hard to tell from the plots how much more 'pup'-ular the different dog types are compared to one another, so some calculations were in order.\n",
    "\n",
    "Since favorite counts and retweet counts appear to be rising exponentially, the 'average' for any dog type would be skewed severely by posts that had gone viral. Instead, looking at the median number of favorites and retweet for the dog types, we see that puppers are abysmally low relative to the rest of the pack. My unsubstantiated speculation is that that for the followers of WeRateDogs, the novelty of 'puppers' had worn off."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
