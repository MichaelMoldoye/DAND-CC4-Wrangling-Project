{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Wrangling Report\n",
    "## Michael Mosin\n",
    "#### 300-600 word written report that briefly describes my wrangling efforts. \n",
    "\n",
    "\n",
    "Wrangling began with gathering and importing the data - the WeRateDogs Twitter archive data, the image prediction data, and the additional JSON Twitter data. The archive data (`twitter-archive-enhanced.csv`) and JSON data (`tweet_json.txt`) were downloaded from the project resources. The archive was read into a Pandas DataFrame as a CSV file, while the JSON data had to be extracted line by line from a .txt file using the `os` Python library before being converted into a Pandas DataFrame. The image prediction data had to be imported from a URL using the `requests` Python library, and then read into a Pandas DataFrame from a TSV file.\n",
    "\n",
    "Assessing the data for quality and tidiness issues always initially involved using the `.head` method to see the first few entries with full view of all the columns and their values. THat was then followed by using the `.info` method to clarify the number of variables, number of non-null values for each of them, and their datatype. For the archive dataset, this lead to exploring the structure of its dog type classifications, rating consistency, validity of names, and figuring out how to determine which Tweets were not originals. \n",
    "\n",
    "To prepare the data for visual assessment, I often programmatically isolated different subsets of the dataset entries based on a specific characteristic, such as the name being `a` or the rating denominator being different from `10`. Another tool I used often for assessment was the `.value_counts()` method to see the different values within a certain variable, how many were unique, and how often they repeated.\n",
    "\n",
    "Assessing the image prediction data involved clarifying how many entries did not have any positive dog predictions by applying similar conditional dataset segmentation. Assessing the JSON data revealed that there were some variables which contained multiple pieces of information (nested JSON). If the data within those categories had been of interest, it would have involved creating more variables within the main JSON dataset to hold extracted pieces from these dense entries.\n",
    "\n",
    "Upon trying to reorganize the dog type variables in the archive dataset, I discovered that some entries had more than one dog type extracted. This countered my assumption that the dog type columns were mutually exclusive.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
